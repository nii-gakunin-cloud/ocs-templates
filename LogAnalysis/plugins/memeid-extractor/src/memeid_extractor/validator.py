# SPDX-FileCopyrightText: 2025-present NII Gakunin Cloud <cld-office-support@nii.ac.jp>
#
# SPDX-License-Identifier: Apache-2.0
"""
CSV Validation Module for memeid-extractor.

This module provides validation functionality for CSV files generated by memeid-extractor.
It checks for missing meme IDs and duplicate values according to specified rules.
"""

from collections import defaultdict
from logging import getLogger
from pathlib import Path
from typing import TYPE_CHECKING, Any, NotRequired, TypedDict

if TYPE_CHECKING:
    from memeid_extractor.extractor import ExtractedData

logger = getLogger(__name__)


class ValidationError(TypedDict):
    """Information about a validation error."""

    error_type: str
    message: str
    row_number: int
    field_name: str
    field_value: str
    additional_info: NotRequired[str]
    textbook_path: str
    structured_data: NotRequired[dict[str, Any]]


class ValidationResult(TypedDict):
    """Result of CSV validation."""

    is_valid: bool
    errors: list[ValidationError]
    total_rows: int
    valid_rows: int


class ValidatorArgs(TypedDict):
    """Arguments for CSV validation."""

    csv_file: Path
    strict_mode: bool
    enabled: bool
    display_mode: NotRequired[str]


# =============================================================================
# ValidationError Factory Functions
# =============================================================================


def _create_missing_value_error(field_name: str, row_number: int, textbook_path: str = "") -> ValidationError:
    """
    Create a missing_value ValidationError for missing meme ID fields.

    Args:
        field_name (str): Name of the missing field (lc_cell_meme or lc_notebook_meme)
        row_number (int): Row number where the missing value was found
        textbook_path (str): Textbook path for additional context

    Returns:
        ValidationError: Formatted validation error for missing value
    """
    return ValidationError(
        error_type="missing_value",
        message=f"Missing {field_name} value",
        row_number=row_number,
        field_name=field_name,
        field_value="",
        textbook_path=textbook_path,
        additional_info=f"textbook_path: {textbook_path}",
    )


def _create_duplicate_value_error(
    cell_meme: str,
    row_number: int,
    first_occurrence_row: int,
    textbook_path: str = "",
) -> ValidationError:
    """
    Create a duplicate_value ValidationError for lc_cell_meme duplicates.

    Args:
        cell_meme (str): The duplicate lc_cell_meme value
        row_number (int): Row number where the duplicate was found
        first_occurrence_row (int): Row number of the first occurrence
        textbook_path (str): Textbook path for additional context

    Returns:
        ValidationError: Formatted validation error for duplicate cell meme
    """
    return ValidationError(
        error_type="duplicate_value",
        message=f"Duplicate lc_cell_meme value: {cell_meme}",
        row_number=row_number,
        field_name="lc_cell_meme",
        field_value=cell_meme,
        textbook_path=textbook_path,
        additional_info=f"First occurrence at row {first_occurrence_row}, textbook_path: {textbook_path}",
        structured_data={
            "first_occurrence_row": first_occurrence_row,
        },
    )


def _create_inconsistent_correspondence_error(
    textbook_path: str,
    notebook_meme: str,
    row_number: int,
    expected_meme: str,
    first_row: int,
) -> ValidationError:
    """
    Create an inconsistent_correspondence ValidationError for same path with different notebook meme.

    Args:
        textbook_path (str): The textbook path with inconsistent meme
        notebook_meme (str): The notebook meme value found
        row_number (int): Row number where the inconsistency was found
        expected_meme (str): The expected notebook meme value
        first_row (int): Row number where the expected meme was first seen

    Returns:
        ValidationError: Formatted validation error for inconsistent correspondence
    """
    return ValidationError(
        error_type="inconsistent_correspondence",
        message="Same textbook_path has different lc_notebook_meme values",
        row_number=row_number,
        field_name="lc_notebook_meme",
        field_value=notebook_meme,
        textbook_path=textbook_path,
        additional_info=f"textbook_path: {textbook_path}, expected: {expected_meme} (first seen at row {first_row})",
        structured_data={
            "expected_meme": expected_meme,
            "first_row": first_row,
        },
    )


def _create_duplicate_meme_different_path_error(
    notebook_meme: str,
    textbook_path: str,
    row_number: int,
    expected_path: str,
    first_row: int,
) -> ValidationError:
    """
    Create a duplicate_meme_different_path ValidationError for same meme with different path.

    Args:
        notebook_meme (str): The notebook meme with different path
        textbook_path (str): The textbook path found
        row_number (int): Row number where the different path was found
        expected_path (str): The expected textbook path
        first_row (int): Row number where the expected path was first seen

    Returns:
        ValidationError: Formatted validation error for duplicate meme with different path
    """
    return ValidationError(
        error_type="duplicate_meme_different_path",
        message="Different textbook_path has same lc_notebook_meme value",
        row_number=row_number,
        field_name="textbook_path",
        field_value=textbook_path,
        textbook_path=textbook_path,
        additional_info=f"lc_notebook_meme: {notebook_meme}, expected path: {expected_path} (first seen at row {first_row})",
        structured_data={
            "expected_path": expected_path,
            "first_row": first_row,
            "notebook_meme": notebook_meme,
        },
    )


# =============================================================================
# Validation Helper Functions
# =============================================================================


def _validate_missing_values(rows: list[dict[str, str]]) -> list[ValidationError]:
    """
    Validate for missing meme ID values.

    Args:
        rows (list[dict[str, str]]): CSV rows to validate

    Returns:
        list[ValidationError]: List of validation errors for missing values
    """
    errors = []

    for row_num, row in enumerate(rows, start=1):
        textbook_path = row.get("textbook_path", "")

        # Check for missing lc_cell_meme
        if not row.get("lc_cell_meme", "").strip():
            errors.append(
                _create_missing_value_error(
                    field_name="lc_cell_meme",
                    row_number=row_num,
                    textbook_path=textbook_path,
                )
            )

        # Check for missing lc_notebook_meme
        if not row.get("lc_notebook_meme", "").strip():
            errors.append(
                _create_missing_value_error(
                    field_name="lc_notebook_meme",
                    row_number=row_num,
                    textbook_path=textbook_path,
                )
            )

    return errors


def _validate_cell_meme_duplicates(rows: list[dict[str, str]]) -> list[ValidationError]:
    """
    Validate that lc_cell_meme values are unique across the CSV file.

    Args:
        rows (list[dict[str, str]]): CSV rows to validate

    Returns:
        list[ValidationError]: List of validation errors for cell meme duplicates
    """
    errors = []
    cell_meme_rows: dict[str, list[int]] = defaultdict(list)

    # Collect all lc_cell_meme values and their row numbers
    for row_num, row in enumerate(rows, start=1):
        if not (cell_meme := row.get("lc_cell_meme", "").strip()):
            continue  # Skip rows with missing lc_cell_meme
        cell_meme_rows[cell_meme].append(row_num)

    # Find duplicates
    for cell_meme, row_numbers in cell_meme_rows.items():
        if len(row_numbers) == 1:
            continue  # No duplicates, skip

        # Report all occurrences after the first one as errors
        for row_num in row_numbers[1:]:
            textbook_path = rows[row_num - 1].get("textbook_path", "").strip()
            errors.append(
                _create_duplicate_value_error(
                    cell_meme=cell_meme,
                    row_number=row_num,
                    first_occurrence_row=row_numbers[0],
                    textbook_path=textbook_path,
                )
            )

    return errors


def _validate_notebook_meme_correspondence(rows: list[dict[str, str]]) -> list[ValidationError]:
    """
    Validate 1:1 correspondence between textbook_path and lc_notebook_meme.

    Rules:
    - Same textbook_path must have same lc_notebook_meme
    - Different textbook_path must have different lc_notebook_meme

    Args:
        rows (list[dict[str, str]]): CSV rows to validate

    Returns:
        list[ValidationError]: List of validation errors for notebook meme correspondence
    """
    errors = []
    path_to_meme: dict[str, tuple[str, int]] = {}  # textbook_path -> (lc_notebook_meme, first_row)
    meme_to_path: dict[str, tuple[str, int]] = {}  # lc_notebook_meme -> (textbook_path, first_row)

    for row_num, row in enumerate(rows, start=1):
        textbook_path = row.get("textbook_path", "").strip()
        notebook_meme = row.get("lc_notebook_meme", "").strip()

        # Skip rows with missing values (handled by _validate_missing_values)
        if not textbook_path or not notebook_meme:
            continue

        # Check path -> meme correspondence
        if textbook_path in path_to_meme:
            expected_meme, first_row = path_to_meme[textbook_path]
            if notebook_meme != expected_meme:
                errors.append(
                    _create_inconsistent_correspondence_error(
                        textbook_path=textbook_path,
                        notebook_meme=notebook_meme,
                        row_number=row_num,
                        expected_meme=expected_meme,
                        first_row=first_row,
                    )
                )
        else:
            path_to_meme[textbook_path] = (notebook_meme, row_num)

        # Check meme -> path correspondence
        if notebook_meme in meme_to_path:
            expected_path, first_row = meme_to_path[notebook_meme]
            if textbook_path != expected_path:
                errors.append(
                    _create_duplicate_meme_different_path_error(
                        notebook_meme=notebook_meme,
                        textbook_path=textbook_path,
                        row_number=row_num,
                        expected_path=expected_path,
                        first_row=first_row,
                    )
                )
        else:
            meme_to_path[notebook_meme] = (textbook_path, row_num)

    return errors


def _validate_duplicates(rows: list[dict[str, str]]) -> list[ValidationError]:
    """
    Validate for duplicate meme ID values according to business rules.

    Rules:
    - lc_cell_meme must be unique across the entire CSV file
    - lc_notebook_meme must have 1:1 correspondence with textbook_path

    Args:
        rows (list[dict[str, str]]): CSV rows to validate

    Returns:
        list[ValidationError]: List of validation errors for duplicates
    """
    errors = []

    # Validate lc_cell_meme uniqueness
    errors.extend(_validate_cell_meme_duplicates(rows))

    # Validate lc_notebook_meme correspondence with textbook_path
    errors.extend(_validate_notebook_meme_correspondence(rows))

    return errors


# =============================================================================
# Main Functions
# =============================================================================


def validate_extracted_data(data: "ExtractedData") -> ValidationResult:
    """
    Validate extracted data before CSV generation.

    This function validates ExtractedData directly without requiring CSV file I/O,
    providing better performance and allowing pre-generation validation.

    This is the primary validation function used in the extraction workflow.

    Args:
        data (ExtractedData): Extracted data containing cells and metadata.

    Returns:
        ValidationResult: Validation result containing errors and statistics.
    """
    if not data["cells"]:
        return ValidationResult(
            is_valid=True,
            errors=[],
            total_rows=0,
            valid_rows=0,
        )

    # Convert ExtractedCellData to dict format for validation functions
    rows = []
    for cell_data in data["cells"]:
        row = {
            "lc_cell_meme": cell_data["lc_cell_meme"] or "",
            "lc_notebook_meme": cell_data["lc_notebook_meme"] or "",
            "textbook_path": cell_data["textbook_path"],
        }
        rows.append(row)

    errors = []
    errors.extend(_validate_missing_values(rows))
    errors.extend(_validate_duplicates(rows))

    return ValidationResult(
        is_valid=len(errors) == 0,
        errors=errors,
        total_rows=len(rows),
        valid_rows=len(rows) - len(errors),
    )


def _display_normal_validation_results(result: ValidationResult) -> None:
    """
    Display validation results in normal mode.

    Shows errors grouped by textbook_path, without row number information,
    with duplicate information removed.

    Args:
        result (ValidationResult): Validation result to display
    """
    if result["is_valid"]:
        logger.info("CSV validation passed: %d rows validated successfully", result["total_rows"])
        return

    # Check for inconsistent_correspondence errors (bug detection)
    if any(error["error_type"] == "inconsistent_correspondence" for error in result["errors"]):
        msg = "Detected inconsistent_correspondence errors, indicating a bug in the validation logic."
        logger.error(msg)
        raise RuntimeError(msg)

    # Group errors by textbook_path
    path_groups: dict[str, list[ValidationError]] = defaultdict(list)
    for error in result["errors"]:
        if error["error_type"] != "inconsistent_correspondence":
            path_groups[error["textbook_path"]].append(error)

    if not path_groups:
        return  # No relevant errors to display

    # Display grouped results
    logger.warning("Validation errors found:")
    error_paths = sorted(path_groups.keys())

    for textbook_path in error_paths:
        logger.warning("  %s:", textbook_path)
        group_errors = path_groups[textbook_path]

        # Missing values - show specific field names
        missing_fields = {error["field_name"] for error in group_errors if error["error_type"] == "missing_value"}
        if missing_fields:
            logger.warning("    Missing values: %s", ", ".join(sorted(missing_fields)))

        # Duplicate values - show specific field names (includes both duplicate types)
        duplicate_fields = {
            error["field_name"]
            for error in group_errors
            if error["error_type"] in ("duplicate_value", "duplicate_meme_different_path")
        }
        if duplicate_fields:
            logger.warning("    Duplicate values: %s", ", ".join(sorted(duplicate_fields)))

        # Path conflicts - detailed display preserved
        path_conflicts = {
            expected_path
            for error in group_errors
            if error["error_type"] == "duplicate_meme_different_path"
            and (expected_path := error.get("structured_data", {}).get("expected_path"))
        }
        if path_conflicts:
            logger.warning("    Path conflicts: %s", ", ".join(sorted(path_conflicts)))

    # Display operation guide
    _display_fix_guide(error_paths)


def _display_fix_guide(error_paths: list[str]) -> None:
    """
    Display operation guide for fixing validation errors.

    Args:
        error_paths (list[str]): List of textbook paths with validation errors
    """
    if not error_paths:
        return

    logger.info("")  # Empty line for separation
    logger.info("To fix these errors, run:")
    for path in error_paths:
        # Generate output filename using pathlib for robust path manipulation
        path_obj = Path(path)
        output_path = path_obj.parent / f"{path_obj.stem}.fixed{path_obj.suffix}"
        logger.info("  jupyter nblineage new-root-meme %s %s", path, str(output_path))
    logger.info("")  # Empty line for separation


def display_validation_results(result: ValidationResult, *, display_mode: str = "normal") -> None:
    """
    Display validation results to the user.

    Args:
        result (ValidationResult): Validation result to display
        display_mode (str): Display mode - "quiet", "normal", or "verbose"
    """
    # All modes: DEBUG logging for watch mode diagnostics
    if result["is_valid"]:
        logger.debug("CSV validation passed: %d rows", result["total_rows"])
    else:
        logger.debug(
            "CSV validation failed: %d error(s) in %d rows",
            len(result["errors"]),
            result["total_rows"],
        )

    match display_mode:
        case "quiet":
            # Quiet mode: completely silent (exit code only)
            return
        case "normal":
            # Normal mode: use placeholder implementation
            _display_normal_validation_results(result)
        case "verbose":
            # Verbose mode: detailed output (original behavior)
            _display_verbose_validation_results(result)
        case _:
            msg = f"Invalid display_mode: {display_mode}. Must be 'quiet', 'normal', or 'verbose'."
            raise ValueError(msg)


def _display_verbose_validation_results(result: ValidationResult) -> None:
    """
    Display validation results in verbose mode (normal mode summary + detailed breakdown).

    Args:
        result (ValidationResult): Validation result to display
    """
    if result["is_valid"]:
        logger.info("CSV validation passed: %d rows validated successfully", result["total_rows"])
        return

    # First show normal mode summary
    _display_normal_validation_results(result)

    # Then show detailed breakdown
    error_count = len(result["errors"])
    logger.warning("")  # Empty line for separation
    logger.warning("Detailed breakdown:")
    logger.warning("CSV validation failed: %d error(s) found in %d rows", error_count, result["total_rows"])

    # Group errors by type for better readability
    error_groups: dict[str, list[ValidationError]] = defaultdict(list)
    for error in result["errors"]:
        error_groups[error["error_type"]].append(error)

    for error_type, errors in error_groups.items():
        logger.warning("%s: %d error(s)", error_type.replace("_", " ").title(), len(errors))
        max_errors_to_display = 5
        for error in errors[:max_errors_to_display]:  # Limit to first 5 errors per type
            logger.warning("  Row %d: %s", error["row_number"], error["message"])
            if e := error.get("additional_info"):
                logger.warning("    %s", e)

        if len(errors) > max_errors_to_display:
            logger.warning("  ... and %d more error(s) of this type", len(errors) - max_errors_to_display)
